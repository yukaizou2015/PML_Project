diamonds
str(diamonds)
qplot(price, data = diamonds)
range(diamonds$price)
qplot(price, data = diamonds, binwidth = 18497/30)
brk
counts
qplot(price, data = diamonds, binwidth = 18497/30, fill = cut)
qplot(price, data = diamonds, geom = "density")
qplot(price, data = diamonds, geom = "density", color = cut)
qplot(corat, price, data = diamonds)
qplot(carat, price, data = diamonds)
qplot(carat, price, data = diamonds, shape = cut)
qplot(carat, price, data = diamonds, color = cut)
qplot(carat, price, data = diamonds, color = cut, geom = c("point", "smooth"), method = "lm")
qplot(carat, price, data = diamonds, color = cut, geom = c("point", "smooth"), method = "lm", facets = . ~ cut)
g <- ggplot(diamonds, aes(depth, price))
summary(g)
g + geom_point(alpha = 1/3)
cutpoints <- quantile(diamonds$carat, seq(0, 1, length = 4), na.rm = TRUE)
cutpoints
diamonds$car2 <- cut(diamonds$carat, cutpoints)
g <- ggplot(diamonds, aes(depth, price))
g + geom_point(alpha = 1/3) + facet_grid(cut ~ car2)
diamonds[myd,]
g + geom_point(alpha = 1/3) + facet_grid(cut ~ car2) + geom_smooth(method = "lm", size = 3, color = "pink")
ggplot(diamonds, aes(carat, price)) + geom_boxplot() + facet_grid(.~cut)
hist(rexp(40, mean = 1/0.2, sd = 1/0.2))
rexp(40, 0.2)
hist(rexp(40, 0.2))
hist(rexp(1000, 0.2))
mns <- NULL
for (i in 1:1000) mns <- c(mns, mean(rexp(40, rate = 0.2)))
hist(mns)
ggplot(mns)
qplot(mns)
?qplot
?vline
??vline
qplot(mns) + geom_vline(intercept = 0)
qplot(mns) + geom_vline(intercept = 5)
qplot(mns) + geom_vline(intercept = 3)
qplot(mns) + geom_vline(intercept = 3, size = 2)
hist(mns)
abline(v = 5)
?abline
abline(v = 5, lwd = 2)
abline(v = 5, lwd = 3)
mean(mns)
abline(v = mean(mns), lwd = 3)
library(swirl)
swirl()
10/sqrt(100)
2
(32 - 30)/(10/sqrt(16))
15
qt(0.95, 15)
dim(fs)
t.test(fs$sheight, fs$fheight, paired = TRUE)
11.7885 * sd(fs$sheight - fs$fheight)/sqrt(1078)
mybin
8
pt(2.5, df = 15, lower.tail = FALSE)
qnorm(0.95)
qnorm(0.99)
pnorm(2)
pnorm(2, lower.tail = FALSE)
mybin
pbinom(6, size = 8, prob = .5, lower.tail = FALSE)
pbinom(7, size = 8, prob = .5, lower.tail = TRUE)
ppois(9, lambda = 5, lower.tail = FALSE)
library(UsingR)
data(galton)
par(mfrow = c(1,2))
hist(galton$child, col = "blue", breaks = 100)
hist(galton$parent, col = "blue", breaks = 100)
library(manipulate)
library(manipulate)
myHist <- function(mu){
hist(galton$child, col = "blue", breaks = 100)
lines(c(mu, mu), c(0, 150), col = "red", lwd = 5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
dev.off()
library(manipulate)
myHist <- function(mu){
hist(galton$child, col = "blue", breaks = 100)
lines(c(mu, mu), c(0, 150), col = "red", lwd = 5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
mean(galton$child)
plot(galton$parent, galton$child, pch = 19, col = "blue")
library()
swirl()
library(swirl)
swirl()
head(pValues)
sum(pValues < 0.05)
p.adjust(pValues, method = "bonferroni")
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
sum(p.adjust(pValues, method = "BH") < 0.05)
tail(trueStatus)
table(pValues2 < 0.05, trueStatus)
24/500
table(p.adjust(pValues2, method = "bonferroni") < 0.5, trueStatus)
table(p.adjust(pValues2, method = "bonferroni") < 0.05, trueStatus)
table(p.adjust(pValues2, method = "BH") < 0.05, trueStatus)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
x
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- cor(y,x) * sd(y)/sd(x)
beta0 <- mean(y) - beta1 * mean(x)
c(beta0, beta1)
data(mtcars)
head(mtcars)
y <- mtcars$mpg
x <- mtcars$wt
coef(lm(y~x))
beta1 <- cor(y,x) * sd(y)/sd(x)
beta0 <- mean(y) - beta1 * mean(x)
c(beta0, beta1)
beta1 <- 0.5 * 1/2
beta1
1.5 * 0.4
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(x ~ y))
coef(lm(y ~ x))
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xn <- (x - mean(x))/sd(x)
xn
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
y * x
x^2
sum(y * x) / sum( x^2 )
x <- c(0.18, -1.54, 0.42, 0.95)
mean(x)
mu <- c(0.300, 0.0025, 0.1471, 1.077)
mu
w
w * (x - mu)^2
w * (x - mu[1])^2
sum(w * (x - mu[1])^2)
sum(w * (x - mu[2])^2)
sum(w * (x - mu[3])^2)
sum(w * (x - mu[4])^2)
sum(w)
sum(w * x)
mu <- c(0.300, 0.0025, 0.1471, 1.077)
2.06 * mu - 7 * mu^2
library(swirl)
install_from_swirl("Regression Models")
swirl()
0.75/0.48
(0.75 * 0.3) / (0.75 * 0.3 + 0.48 * 0.7)
pnorm(0.95)
qnorm(0.95)
qnorm(0.95, mean = 1100, sd = 75)
qnorm(0.95, mean = 1100, sd = 75/sqrt(100))
pnorm(90, mean = 80, sd = 10)
p <- pnorm(90, mean = 80, sd = 10)
choose(5, 4) * p^4 * (1-p) + choose(5, 5) * p^5
p <- pnorm(90, mean = 80, sd = 10, lower.tail = FALSE)
p
choose(5, 4) * p^4 * (1-p) + choose(5, 5) * p^5
p <- pnorm(90, mean = 80, sd = 10/sqrt(5), lower.tail = FALSE)
p
choose(5, 4) * p^4 * (1-p) + choose(5, 5) * p^5
choose(5, 4) * 0.5^5 + choose(5, 5) * 0.5^5
15 + c(-1,1) * qt(0.84, 99) * 1
library(datasets)
library(ggplot2)
data(mtcars)
hear(mtcars)
head(mtcars)
auto <- mtcars[mtcars$am == 1,]
auto <- mtcars[mtcars$am == 0,]
manual <- mtcars[mtcars$am == 1, ]
?mtcars
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_point()
g
g <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
g <- g + geom_point()
g
g <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
g <- g + geom_dotplot()
g
g <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
g <- g + geom_point()
g
g <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
g <- g + geom_bar(stat = "bin")
g
g <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
g <- g + geom_bar(stat = "identity")
g
?geom_boxplot
g <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
g <- g + geom_boxplot()
g
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_point()
g
library(UsingR)
e = c(resid(lm(price ~ 1, data = diamond)),
resid(lm(price ~ carat, data = diamond)))
fit = factor(c(rep("Itc", nrow(diamond)),
rep("Itc, slope", nrow(diamond))))
g = ggplot(data.frame(e = e, fit = fit), aes(y = e, x = fit, fill = fit))
g = g + geom_dotplot(binaxis = "y", size = 2, stackdir = "center", binwidth = 20)
g = g + xlab("Fitting approach")
g = g + ylab("Residual price")
g
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_point(size = 2)
g
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_dotplot(binaxis = "y", size = 2, stackdir = "center", binwidth = 20)
g
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_dotplot(binaxis = "y", size = 2, stackdir = "center")
g
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_dotplot(binaxis = "y", size = 1, stackdir = "center")
g
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_dotplot(binaxis = "x", size = 1, stackdir = "center")
g
g <- ggplot(mtcars, aes(x = am, y = mpg))
g <- g + geom_point()
g
?geom_boxplot
p <- ggplot(mtcars, aes(factor(cyl), mpg))
p + geom_boxplot()
g <- ggplot(mtcars, aes(x = factor(am), y = mpg))
g <- g + geom_boxplot()
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = am))
g <- g + geom_boxplot()
g
?geom_axis
?xaxis
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = am))
g <- g + geom_boxplot()
g <- g + xlab("Mode")
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = am))
g <- g + geom_boxplot()
g <- g + xlab("Modes of Transmission")
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = am))
g <- g + geom_boxplot()
g <- g + xlab("Modes of Transmission")
g <- g + ylab("Miles per Gallon")
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = am))
g <- g + geom_boxplot()
g <- g + xlab("Modes of transmission")
g <- g + ylab("Miles per gallon")
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = am))
g <- g + geom_boxplot()
g <- g + xlab("Modes of transmission") + scale_x_discrete(labels = c("automatic", "manual"))
g <- g + ylab("Miles per gallon")
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = am))
g <- g + geom_boxplot()
g <- g + xlab("Modes of transmission") + scale_x_discrete(labels = c("automatic", "manual"))
g <- g + ylab("Miles per gallon")
g <- g + theme(legend.position = "n")
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg))
g <- g + geom_boxplot()
g <- g + xlab("Modes of transmission") + scale_x_discrete(labels = c("automatic", "manual"))
g <- g + ylab("Miles per gallon")
g <- g + theme(legend.position = "n")
g <- g + heat.color()
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg))
g <- g + geom_boxplot()
g <- g + xlab("Modes of transmission") + scale_x_discrete(labels = c("automatic", "manual"))
g <- g + ylab("Miles per gallon")
g <- g + theme(legend.position = "n")
g <- g + heat.colors()
g
g <- ggplot(mtcars, aes(x = factor(am), y = mpg, fill = factor(am)))
g <- g + geom_boxplot()
g <- g + xlab("Modes of transmission") + scale_x_discrete(labels = c("automatic", "manual"))
g <- g + ylab("Miles per gallon")
g <- g + theme(legend.position = "n")
g
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
?fit
fit <- lm(y ~ x)
round(hatvalues(fit), 3)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
round(dfbetas(fit), 4)
data(mtcars)
head(mtcars)
x1 <- mtcars$cyl # cylinder variable
x2 <- mtcars$wt # confounder (weight)
y <- mtcars$mpg
fit <- lm(y ~ x1)
fit
fit2 <- lm(y ~ x1 + x2)
fit2
fit2 <- lm(y ~ x1 - x2)
fit2
fit2 <- lm(y ~ x1 + x2)
fit2
fit <- lm(y ~ factor(x1))
fit
fit2 <- lm(y ~ factor(x1) + x2)
fit2
fit
fit2
plot(type = "n")
plot(x = x1, y = y, type = "n")
plot(x = x1, y = y)
mtcars$cyl
mtcars$cyl[mtcars$cyl == 6]
mtcars[mtcars$cyl == 4 | mtcars$cyl == 8, ]
dat <- mtcars[mtcars$cyl == 4 | mtcars$cyl == 8, ]
y <- dat$mpg
x1 <- dat$cyl # cylinder variable
x2 <- dat$wt # confounder (weight)
fit <- lm(y ~ factor(x1))
fit2 <- lm(y ~ factor(x1) + x2) # using factor function is important so that x1 won't be
fit2
fit1
fit
summary(fit2)$coefficients
fit2
fit <- lm(mpg ~ cyl, data = mtcars)
fit
summary(fit)$coefficients
fit <- lm(mpg ~ factor(cyl), data = mtcars)
summary(fit)$coefficients
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
summary(fit)$coefficients
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
summary(fit)$coefficients[3]
fit <- lm(mpg ~ factor(cyl), data = mtcars) # slide 9/35
summary(fit)$coefficients
fit2 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
summary(fit2)$coefficients
c(summary(fit)$coefficients[3], summary(fit2)$coefficients[3])
c(a = summary(fit)$coefficients[3], b = summary(fit2)$coefficients[3])
c(unadjusted = summary(fit)$coefficients[3],
adjusted = summary(fit2)$coefficients[3])
fit <- lm(mpg ~ factor(cyl), data = mtcars)
fit2 <- lm(mpg ~ factor(cyl)*wt, data = mtcars)
summary(fit)$coefficients
summary(fit2)$coefficients
data(mtcars)
fit <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit2 <- lm(mpg ~ I(wt * 1) + factor(cyl), data = mtcars)
summary(fit2)$coefficients
summary(fit)$coefficients
?I
summary(fit)$coefficients
summary(fit2)$coefficients
?mtcars
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl)*wt, data = mtcars)
summary(fit)$coefficients
summary(fit2)$coefficients # how to interpret P value?
# Question 4
data(mtcars)
fit <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit2 <- lm(mpg ~ I(wt * 1) + factor(cyl), data = mtcars)
summary(fit)$coefficients
summary(fit2)$coefficients
lm(mpg ~ I(wt * 2) + factor(cyl), data = mtcars)
summary(lm(mpg ~ I(wt * 2) + factor(cyl), data = mtcars))$coefficients
lm(mpg ~ I(wt * 2) + factor(cyl), data = mtcars)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
I(wt * 0.5)
I(mtcars$wt * 0.5)
I(mtcars$wt * 1)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
lm(y ~ x)
lm(y ~ x * 0.5)
lm(y ~ I(x * 0.5))
lm(y ~ I(x * 1))
data(mtcars)
fit <- lm(mpg ~ factor(cyl), data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
summary(fit)$coefficients
summary(fit2)$coefficients
c(unadjusted = summary(fit)$coefficients[3],
adjusted = summary(fit2)$coefficients[3])
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
round(dfbetas(fit), 4)
round(hatvalues(fit), 3)
library(XML)
?xpathApply
data(iris)
library(ggplot2)
news(Version == "1.0.1", package = "ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Pedal.Width, Sepal.Width, colour=Species, data=training)
qplot(Pedal.Width, Sepal.Width, colour=Species, data=training, data = iris)
?qplot
qplot(Pedal.Width, Sepal.Width, data = iris, colour=Species, data=training)
names(iris)
qplot(Pedal.Width, Sepal.Width, colour=Species, data=training)
names(training)
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
modFit <- train(Species ~ ., method = "rpart", data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.package("rpart.plot")
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata=testing)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(ozone, package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone)]
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA, nrow=10, ncol=155)
ss <- sample(1:dim(ozone)[1], replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2j)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
for (i in 1:10){
ss <- sample(1:dim(ozone)[1], replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5)
for(i in 1:10){lines(1:155, ll[i,], col="grey", lwd=2)}
lines(1:155, apply(ll,2,mean), col="red", lwd = 2)
library(caret); library(randomForest); library(dplyr)
setwd("~/Desktop/Coursera/Practical Machine Learning/PML_Project/")
training <- read.csv("pml-training.csv", na.strings = c("NA", "")); training.NAlist <- grep("NA", training); training <- select(training, -training.NAlist)
testing <- read.csv("pml-testing.csv", na.strings = c("NA", "")); testing.NAlist <- grep("NA", testing); testing <- select(testing, -testing.NAlist)
training[,-length(training)] <- data.frame(sapply(training[,-length(training)], as.numeric))
testing[,-length(testing)] <- data.frame(sapply(testing[,-length(testing)], as.numeric))
write.csv(training, "pml-training_processed.csv", row.names=FALSE)
write.csv(testing, "pml-testing_processed.csv", row.names=FALSE)
inTrain <- createDataPartition(y=training$X, p=0.7, list=FALSE)
training.train <- training[inTrain,]; write.csv(training.train, file = "pml-training_train.csv", row.names = FALSE)
training.test <- training[-inTrain,]; write.csv(training.test, file = "pml-training_test.csv", row.names = FALSE)
modFit <- train(classe ~ ., method = "lda", data = training.train[,-c(1,2)]); saveRDS(modFit, "mySavedModel001.rds")
modFit.time <- system.time(train(classe ~ ., method = "lda", data = training.train[,-c(1,2)]))
modFit2 <- train(classe ~ ., method = "rpart", data = training.train[,-c(1,2)]); saveRDS(modFit2, "mySavedModel002.rds")
modFit2.time <- system.time(train(classe ~ ., method = "rpart", data = training.train[,-c(1,2)]))
modFit3 <- randomForest(classe ~ ., data = training.train[,-c(1,2)]); saveRDS(modFit3, "mySavedModel003.rds")
modFit3.time <- system.time(randomForest(classe ~ ., data = training.train[,-c(1,2)]))
mod.time <- data.frame(lda = as.matrix(modFit.time)[3], rpart = as.matrix(modFit2.time)[3],
randomForest = as.matrix(modFit3.time)[3], row.names = "elapsed time (sec)")
mod.time
write.table(mod.time, "3 Models_elapsed time.txt")
answers1 <- predict(modFit, training.test[,-c(1,2,length(training.test))])
answers2 <- predict(modFit2, training.test[,-c(1,2,length(training.test))])
answers3 <- predict(modFit3, training.test[,-c(1,2,length(training.test))])
write.table(answers1, "answers1.txt"); write.table(answers2, "answers2.txt"); write.table(answers3, "answers3.txt")
confusionMatrix(training.test$classe, answers1)
confusionMatrix(training.test$classe, answers2)
confusionMatrix(training.test$classe, answers3)
finalMod <- randomForest(classe ~ ., data = training[,-c(1,2)]); saveRDS(finalMod, "mySavedModel_final.rds")
finalMod.predict <- predict(finalMod, newdata = testing[,-c(1,2,length(testing))])
finalMod.predict
finalMod <- randomForest(classe ~ ., data = training[,-c(1,2)]); saveRDS(finalMod, "mySavedModel_final.rds")
finalMod.predict <- predict(finalMod, newdata = testing[,-c(1,2,length(testing))])
finalMod.predict
confusionMatrix(training.test$classe, answers2)
confusionMatrix(training.test$classe, answers1)
confusionMatrix(training.test$classe, answers3)
answers2 <- predict(modFit2, training.test[,-c(1,2,length(training.test))])
confusionMatrix(training.test$classe, answers2)
